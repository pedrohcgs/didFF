% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/didFF.R
\name{didFF}
\alias{didFF}
\title{Test if Parallel trends assumption is sensitive to functional form}
\usage{
didFF(
  data,
  yname,
  tname,
  idname,
  gname,
  weightsname = NULL,
  est_method = "dr",
  xformla = NULL,
  panel = TRUE,
  allow_unbalanced_panel = FALSE,
  nevertreated = NULL,
  control_group = base::c("nevertreated", "notyettreated"),
  anticipation = 0,
  nbins = NULL,
  binpoints = NULL,
  numSims = 1e+05,
  seed = 0,
  lb_graph = NULL,
  ub_graph = NULL,
  aggte_type = "group",
  balance_e = NULL,
  min_e = -Inf,
  max_e = Inf,
  distDD = FALSE,
  pl = FALSE,
  cores = parallel::detectCores()
)
}
\arguments{
\item{data}{The name of the data.frame that contains the data}

\item{yname}{The name of the outcome variable}

\item{tname}{The name of the column containing the time periods}

\item{idname}{The cross-sectional unit id name}

\item{gname}{The name of the variable in \code{data} that
contains the first period when a particular observation is treated.
This should be a positive number for all observations in treated groups.
It defines which "group" a unit belongs to.  It can be \code{0}  or \code{Inf} for units
in the ``never-treated'' group.}

\item{weightsname}{The name of the column containing the sampling weights.
If not set, all observations have the same weight (Default is NULL).}

\item{est_method}{the method to compute group-time average treatment effects.
The default is "dr" which uses the doubly robust
approach in the \code{DRDID} package.  Other built-in methods
include "ipw" for inverse probability weighting and "reg" for
first step regression estimators.}

\item{xformla}{A formula for the covariates to include in the
model.  It should be of the form \code{~ X1 + X2}.  Default
is NULL which is equivalent to \code{xformla=~1}.  This is
used to create a matrix of covariates which is then passed
to the 2x2 DID estimator chosen in \code{est_method}.}

\item{panel}{Whether or not the data is a panel dataset.
The panel dataset should be provided in long format -- that
is, where each row corresponds to a unit observed at a
particular point in time.  The default is TRUE.
When \code{panel=FALSE}, the data is treated
as repeated cross sections.}

\item{allow_unbalanced_panel}{Whether or not function should
"balance" the panel with respect to time and id.  The default
value is \code{FALSE} which means that \code{\link[=att_gt]{att_gt()}} will drop
all units where data is not observed in all periods.}

\item{nevertreated}{A scalar indicating never treated cohort. If any cohorts are equal to 0
and all time periods are above 0, then the 0 cohort is taken as never-treated by default;
otherwise the default is Inf.}

\item{control_group}{Which units to use the control group.
The default is \code{control_group = "nevertreated"}, which sets the control group
to be the group of units that never participate in the
treatment.  This group does not change across groups or
time periods.  The other option is to set
\code{control_group="notyettreated"}.  In this case, the control group
is set to the group of units that have not yet participated
in the treatment in that time period.  This includes all
never treated units, but it includes additional units that
eventually participate in the treatment, but have not
participated yet.}

\item{anticipation}{The number of time periods before participating
in the treatment where units can anticipate participating in the
treatment and therefore it can affect their untreated potential outcomes}

\item{nbins}{A scalar indicating the (maximum) number of bins for the support of outcome.
By default, if the outcome has fewer than 20 values then it is taken to be a discrete
variable; otherwise \code{nbins=20} is used. Empty bins dropped.}

\item{binpoints}{Alternative to nbins: A vector indicating the interval endpoints to use;
if the data range is not included then \code{min(y)} and \code{max(y)} are added as endpoints. For
a user-specified vector \code{a = c(a_1, a_2, ..., a_n)}, let \code{b = a} if \code{min(y) >= min(a)}
and \code{b = c(min(y), a)} otherwise; then let \code{c = b} if \code{max(y) <= max(a)} and
\code{c = c(b, max(y))} otherwise. Bins are \verb{[c_1, c_2]}, \verb{(c_2, c_3]}, ..., \verb{(c_\{n-1\}, c_n]}.
Empty bins are dropped.  By default, if the outcome has fewer than
20 values then it is taken to be a discrete variable and its values
are used as bin points. Otherwise \code{nbins} is used.}

\item{numSims}{Number of simulation draws to compute p-value for moment inequality
test. Default \code{numSims=100000}.}

\item{seed}{Starting seed for moment inequality test. Default is seed=0, set seed=NULL for random seed.}

\item{lb_graph}{For display only; smallest bin to be plotted.}

\item{ub_graph}{For display only; largest bin to be plotted.}

\item{aggte_type}{Which type of (scalar) aggregated treatment effect parameter to compute.
Options are "simple", "dynamic", "group", and "calendar". Default is \code{group}.}

\item{balance_e}{If set (and if \code{aggte_type = "dynamic"}), it balances
the sample with respect to event time.  For example, if \code{balance.e=2},
it will drop groups that are not exposed to treatment for
at least three periods. (the initial period when \code{e=0} as well as the
next two periods when \code{e=1} and the \code{e=2}).  This ensures that
the composition of groups does not change when event time changes.}

\item{min_e}{For \code{aggte_type = "dynamic"}, this is the smallest event time to compute
dynamic effects for.  By default, \code{min_e = -Inf} so that effects at
all feasible event times are computed.}

\item{max_e}{For \code{aggte_type = "dynamic"}, this is the largest event time to compute
dynamic effects for.  By default, \code{max_e = Inf} so that effects at
all lfeasible event times are computed.}

\item{distDD}{Estimate the distributional treatment effects (the distribution
of \code{Y(1)} minus the implied distribution of \code{Y(0)}, for the treated). Default is FALSE.
The function distDD is provided as a wrapper for \code{distDD=TRUE}.}

\item{pl}{Whether or not to use parallel processing. Default is FALSE.}

\item{cores}{The number of cores to use for parallel processing.
Only relevant if \code{pl = TRUE}.Default is \code{cores = parallel::detectCores()}.}
}
\value{
A list object containing: The plot of the
implied density under the null; a table with the estimated and
implied densities, and the p-value for H0= Implied Density>=0;
the average treatment effects.
}
\description{
Test if Parallel trends assumption is sensitive to functional form
}
\references{
\cite{Roth, Jonathan and Sant'Anna, Pedro H. C. (2023),
"When is Parallel Trends Sensitive to Functional Form?"
Econometrica, vol. 91 (2), pp. 737â€“747, \doi{10.3982/ECTA19402}}
}
